{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AE-only Cross-Dataset Detector (Binary: Benign vs Attack)\n",
    "# - Trains AE on benign-only sequences from train dataset.\n",
    "# - Uses reconstruction error + threshold to detect Attack.\n",
    "# - Per-day reports include overall binary and per-attack (DoS/DDoS) binary\n",
    "#   metrics, each with attack-specific thresholds (PR-curve tuned).\n",
    "# - Supports global or day-specific thresholds (unsupervised).\n",
    "# - Overlap windows by setting stride < seq_len (e.g., stride = seq_len // 2).\n",
    "# ============================================================\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_recall_fscore_support,roc_auc_score,precision_recall_curve\n",
    "   \n",
    "\n",
    "\n",
    "from utilis.constants import DATASET_PATHS\n",
    "#------------------------------------------------------------\n",
    "# 1) Data loader (your function)\n",
    "# ------------------------------------------------------------\n",
    "from utilis.Data_loader import load_and_align_all_data\n",
    "# Returns:\n",
    "# (\n",
    "#   all_combined_dfs,\n",
    "#   all_individual_dfs_by_dataset,\n",
    "#   label_encoder,\n",
    "#   ALL_ENCODED_LABELS,\n",
    "#   common_features,\n",
    "#   broad_label_mapper,\n",
    "#   broad_label_encoder\n",
    "# )\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0=all, 1=info, 2=warning, 3=error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# --- TensorFlow and Keras Imports ---\n",
    "# Ensure you have tensorflow and scikit-learn installed:\n",
    "# pip install tensorflow scikit-learn matplotlib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0eaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bfb0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Utilities\n",
    "# ------------------------------------------------------------\n",
    "def build_sequences_matrix(X, y, seq_len=20, stride=None):\n",
    "    \"\"\"\n",
    "    Build sliding windows from flat arrays.\n",
    "    label = last element label in the window.\n",
    "    - Non-overlapping: stride == seq_len\n",
    "    - Overlapping: stride < seq_len (e.g., seq_len//2 for 50% overlap)\n",
    "    \"\"\"\n",
    "    if stride is None:\n",
    "        stride = seq_len // 2  # non-overlapping by default\n",
    "    n = len(X)\n",
    "    seqs = []\n",
    "    labs = []\n",
    "    for i in range(0, n - seq_len + 1, stride):\n",
    "        seqs.append(X[i:i+seq_len])\n",
    "        labs.append(y[i+seq_len-1])\n",
    "    return np.asarray(seqs), np.asarray(labs)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Deterministic time-ordered split (avoid temporal leakage)\n",
    "# -------------------------------------------------------------------\n",
    "def time_ordered_split(X, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Deterministic split preserving time order: first (1 - val_ratio) -> train,\n",
    "    last val_ratio -> validation. No shuffling, avoids temporal leakage.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    n_val = int(np.floor(val_ratio * n))\n",
    "    n_train = n - n_val\n",
    "    X_tr = X[:n_train]\n",
    "    X_val = X[n_train:]\n",
    "    return X_tr, X_val\n",
    "\n",
    "\n",
    "def train_val_split(X, y, val_ratio=0.1, shuffle=True, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(y))\n",
    "    if shuffle:\n",
    "        rng.shuffle(idx)\n",
    "    n_val = int(len(y) * val_ratio)\n",
    "    val_idx = idx[:n_val]\n",
    "    train_idx = idx[n_val:]\n",
    "    return X[train_idx], y[train_idx], X[val_idx], y[val_idx]\n",
    "\n",
    "def get_benign_id(broad_label_encoder):\n",
    "    return broad_label_encoder.transform([\"Benign\"])[0]\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d05dae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_or_load_ae(\n",
    "        X_train_seq, \n",
    "        seq_len, \n",
    "        n_features, \n",
    "        train_name , \n",
    "        ae_epochs=10, \n",
    "        batch_size=256, \n",
    "        verbose=1,\n",
    "        latent=64,\n",
    "        enc_units=(128,),\n",
    "        dec_units=(128,),\n",
    "        models_dir=\"lstmmodels\",\n",
    "        compile_loaded=False,  # set True if you plan to continue training loaded models\n",
    "        X_val_seq=None,\n",
    "        shuffle_fit=False,\n",
    "        monitor=\"val_loss\",\n",
    "        patience=3,\n",
    "        build_lstm_autoencoder_fn=None  # inject your builder to avoid circular imports\n",
    "):\n",
    "    \"\"\"\n",
    "        Train or load an LSTM Autoencoder (AE) and its Encoder submodel.\n",
    "\n",
    "        - If saved models exist (matching dataset tag), load them.\n",
    "        - Else, train AE on X_train_seq (or a benign-only subset you pass in),\n",
    "        validate with 10% split, save AE/Encoder and history.\n",
    "\n",
    "        Returns:\n",
    "            ae (tf.keras.Model)\n",
    "            encoder (tf.keras.Model)\n",
    "            history (dict)  # {} if not available on load\n",
    "    \"\"\"\n",
    "    if build_lstm_autoencoder_fn is None:\n",
    "        raise ValueError(\"Please pass build_lstm_autoencoder_fn=build_lstm_autoencoder\")\n",
    "    # --- Infer dataset tag ---\n",
    "    if \"2017\" in train_name:\n",
    "        dataset_tag = \"2017\"\n",
    "    elif \"2018\" in train_name:\n",
    "        dataset_tag = \"2018\"\n",
    "    else:\n",
    "        dataset_tag = train_name  # fallback if other dataset names used\n",
    "    \n",
    "    # include key config in filenames to avoid mismatches across runs\n",
    "    cfg_tag = f\"sl{seq_len}_nf{n_features}_lat{latent}_enc{'-'.join(map(str, enc_units))}_dec{'-'.join(map(str, dec_units))}\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    ae_path   = os.path.join(models_dir, f\"ae_{dataset_tag}_{cfg_tag}.h5\")\n",
    "    enc_path  = os.path.join(models_dir, f\"encoder_{dataset_tag}_{cfg_tag}.h5\")\n",
    "    hist_path = os.path.join(models_dir, f\"history_{dataset_tag}_{cfg_tag}.json\")\n",
    "\n",
    "    # validate inputs\n",
    "    if not isinstance(X_train_seq, np.ndarray) or X_train_seq.ndim != 3:\n",
    "        raise ValueError(f\"X_train_seq must be a 3D ndarray (batch, seq_len, n_features); got {type(X_train_seq)} with shape {getattr(X_train_seq, 'shape', None)}\")\n",
    "    if X_train_seq.shape[1] != seq_len or X_train_seq.shape[2] != n_features:\n",
    "        raise ValueError(f\"X_train_seq shape {X_train_seq.shape} does not match seq_len={seq_len}, n_features={n_features}.\")\n",
    "\n",
    "\n",
    "\n",
    "    # attempt to load both models\n",
    "    if os.path.exists(ae_path):\n",
    "        print(f\"[INFO] Found AE at {ae_path}. Attempting to load AE/Encoder for {dataset_tag} (cfg: {cfg_tag}) ...\")\n",
    "        ae = load_model(ae_path, compile=compile_loaded)\n",
    "        if os.path.exists(enc_path):\n",
    "            encoder = load_model(enc_path, compile=False)\n",
    "        else:\n",
    "            # derive encoder from AE if missing\n",
    "            print(f\"[WARN] Encoder file missing. Rebuilding encoder from AE (layer 'latent').\")\n",
    "            encoder = tf.keras.Model(ae.input, ae.get_layer(\"latent\").output, name=\"LSTM_Encoder\")\n",
    "\n",
    "        # optional compile if you will continue training a loaded model\n",
    "        if compile_loaded:\n",
    "            ae.compile(optimizer=optimizers.Adam(1e-3), loss=\"mse\")\n",
    "\n",
    "        history = {}\n",
    "        if os.path.exists(hist_path):\n",
    "            try:\n",
    "                with open(hist_path, \"r\") as f:\n",
    "                    history = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Failed to load history: {e}. Continuing without history.\")\n",
    "                history = {}\n",
    "        return ae, encoder, history\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # else, train fresh\n",
    "    print(f\"[INFO] Training AE for {dataset_tag} (cfg: {cfg_tag}) ...\")\n",
    "\n",
    "    ae, encoder = build_lstm_autoencoder_fn(seq_len=seq_len,\n",
    "                                         n_features=n_features,\n",
    "                                         latent=latent,\n",
    "                                         enc_units=enc_units,\n",
    "                                         dec_units=dec_units\n",
    "                                         )\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=3, restore_best_weights=True)\n",
    "    ckpt = callbacks.ModelCheckpoint(\n",
    "        ae_path, monitor=monitor, save_best_only=True, save_weights_only=False, verbose=1\n",
    "    )\n",
    "\n",
    "    if X_val_seq is not None:\n",
    "\n",
    "        history_obj = ae.fit(\n",
    "            X_train_seq, X_train_seq,\n",
    "            validation_data=(X_val_seq, X_val_seq),\n",
    "            epochs=ae_epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            shuffle=shuffle_fit,\n",
    "            callbacks=[es,ckpt]\n",
    "        )\n",
    "        \n",
    "        # Convert to dict\n",
    "        history = history_obj.history\n",
    "\n",
    "\n",
    "    # Save models\n",
    "     \n",
    "    ae.save(ae_path)\n",
    "    encoder.save(enc_path)\n",
    "\n",
    "    try:\n",
    "        with open(hist_path, \"w\") as f:\n",
    "            json.dump(history, f)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to save history: {e}\")\n",
    "\n",
    "    return ae, encoder, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12c56401",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Threshold helpers (global/day and PR-curve based)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def choose_threshold_day(err_day, q_low=0.60, q_high=0.99, k=6.0, cap_q=0.98):\n",
    "    # Unsupervised day-specific threshold from low-error subset\n",
    "    if err_day.size == 0:\n",
    "        return np.nan\n",
    "    ben_like = err_day[err_day <= np.quantile(err_day, q_low)]\n",
    "    if ben_like.size < max(100, int(0.05 * len(err_day))):\n",
    "        ben_like = err_day\n",
    "    med = np.median(ben_like); mad = np.median(np.abs(ben_like - med)) * 1.4826\n",
    "    thr_rob = med + k * mad\n",
    "    thr_q   = float(np.quantile(ben_like, q_high))\n",
    "    thr_cap = float(np.quantile(err_day, cap_q))\n",
    "    return min(np.median([thr_rob, thr_q]), thr_cap)\n",
    "\n",
    "def choose_threshold_global(benign_train_errors, q=0.995, k=6.0):\n",
    "    # Robust global threshold: min(q-quantile, median + k*MAD)\n",
    "    if benign_train_errors.size == 0:\n",
    "        return 1.0\n",
    "    med = np.median(benign_train_errors)\n",
    "    mad = np.median(np.abs(benign_train_errors - med)) * 1.4826\n",
    "    thr_rob = med + k * mad\n",
    "    thr_q   = float(np.quantile(benign_train_errors, q))\n",
    "    return min(thr_rob, thr_q)\n",
    "\n",
    "\n",
    "def thr_max_f1(err, y_true):\n",
    "    p, r, t = precision_recall_curve(y_true, err)\n",
    "    if t.size == 0:\n",
    "        return None\n",
    "    f1 = (2 * p[:-1] * r[:-1]) / np.clip(p[:-1] + r[:-1], 1e-12, None)\n",
    "    i = int(np.nanargmax(f1))\n",
    "    return float(t[i])\n",
    "\n",
    "def thr_target_precision(err, y_true, target_p=0.60):\n",
    "    p, r, t = precision_recall_curve(y_true, err)\n",
    "    idx = np.where(p[:-1] >= target_p)[0]\n",
    "    if idx.size == 0:\n",
    "        return thr_max_f1(err, y_true)\n",
    "    return float(t[idx[-1]])\n",
    "\n",
    "def choose_day_threshold_by_pr(err_day, y_true_day, fallback_thr, mode=\"max_f1\", target_precision=0.60):\n",
    "    has_ben = (y_true_day == 0).any()\n",
    "    has_att = (y_true_day == 1).any()\n",
    "    if not (has_ben and has_att):\n",
    "        return fallback_thr\n",
    "    if mode == \"max_f1\":\n",
    "        thr = thr_max_f1(err_day, y_true_day)\n",
    "    else:\n",
    "        thr = thr_target_precision(err_day, y_true_day, target_p=target_precision)\n",
    "    return thr if thr is not None else fallback_thr\n",
    "\n",
    "def choose_subset_thr(err_sub, y_true_sub, fallback_thr, mode=\"max_f1\", target_p=0.60):\n",
    "    has_ben = (y_true_sub == 0).any()\n",
    "    has_att = (y_true_sub == 1).any()\n",
    "    if not (has_ben and has_att):\n",
    "        return fallback_thr\n",
    "    if mode == \"max_f1\":\n",
    "        thr = thr_max_f1(err_sub, y_true_sub)\n",
    "    else:\n",
    "        thr = thr_target_precision(err_sub, y_true_sub, target_p=target_p)\n",
    "    return thr if thr is not None else fallback_thr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ed47835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3) Models: LSTM-AE  \n",
    "# ------------------------------------------------------------\n",
    "def build_lstm_autoencoder(seq_len, n_features, latent=64, enc_units=(128,), dec_units=(128,)):\n",
    "    \"\"\"\n",
    "    Simple LSTM Autoencoder:\n",
    "      Encoder: LSTM stacks -> latent (Dense)\n",
    "      Decoder: RepeatVector -> LSTM stacks -> TimeDistributed Dense\n",
    "    \"\"\"\n",
    "    inp = layers.Input(shape=(seq_len, n_features))\n",
    "    x = inp\n",
    "    for i, u in enumerate(enc_units):\n",
    "        x = layers.LSTM(u, return_sequences=True, name=f\"enc_lstm_{i}\")(x)\n",
    "        print(f\"Encoder LSTM {i} output shape: (batch, {seq_len}, {u})\")\n",
    "\n",
    "    x = layers.LSTM(enc_units[-1], return_sequences=False, name=\"enc_final\")(x)\n",
    "    print(f\"Final Encoder output shape: (batch, {enc_units[-1]})\")\n",
    "\n",
    "    z = layers.Dense(latent, activation='linear', name=\"latent\")(x)\n",
    "    print(f\"Latent vector shape: (batch, {latent})\")\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.RepeatVector(seq_len, name=\"repeat_vector\")(z)\n",
    "    print(f\"After RepeatVector: (batch, {seq_len}, {latent})\")\n",
    "\n",
    "    for i, u in enumerate(dec_units):\n",
    "        x = layers.LSTM(u, return_sequences=True, name=f\"dec_lstm_{i}\")(x)\n",
    "        print(f\"Decoder LSTM {i} output shape: (batch, {seq_len}, {u})\")\n",
    "\n",
    "    out = layers.TimeDistributed(layers.Dense(n_features, activation='linear') , name=\"recon\")(x)\n",
    "    print(f\"Reconstruction shape: (batch, {seq_len}, {n_features})\")\n",
    "\n",
    "\n",
    "    ae = models.Model(inp, out, name=\"LSTM_AE\")\n",
    "    ae.summary()\n",
    "    # Return encoder model up to latent\n",
    "    encoder = models.Model(ae.input, ae.get_layer(\"latent\").output, name=\"LSTM_Encoder\")\n",
    "    encoder.summary()\n",
    "\n",
    "    ae.compile(optimizer=optimizers.Adam(1e-3), loss=\"mse\")\n",
    "    return ae, encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259d9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35adc8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading and Preprocessing CIC_IDS_2018 ---\n",
      "[DEBUG] Now processing DDoS1-Tuesday-20-02-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in DDoS1-Tuesday-20-02-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'DDoS attacks-LOIC-HTTP']\n",
      "Harmonized granular labels: {'DDoS', 'Benign'}\n",
      "[DEBUG] Now processing Web1-Thursday-22-02-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in Web1-Thursday-22-02-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'Brute Force -Web', 'Brute Force -XSS', 'SQL Injection']\n",
      "Harmonized granular labels: {'Web Attack - Brute Force', 'Web Attack - SQL Injection', 'Web Attack - XSS', 'Benign'}\n",
      "[DEBUG] Now processing Botnet-Friday-02-03-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in Botnet-Friday-02-03-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'Bot']\n",
      "Harmonized granular labels: {'Benign', 'Botnet'}\n",
      "[DEBUG] Now processing DDoS2-Wednesday-21-02-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in DDoS2-Wednesday-21-02-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'DDOS attack-LOIC-UDP', 'DDOS attack-HOIC']\n",
      "Harmonized granular labels: {'DDoS', 'Benign'}\n",
      "[DEBUG] Now processing Web2-Friday-23-02-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in Web2-Friday-23-02-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'Brute Force -Web', 'Brute Force -XSS', 'SQL Injection']\n",
      "Harmonized granular labels: {'Web Attack - Brute Force', 'Web Attack - SQL Injection', 'Web Attack - XSS', 'Benign'}\n",
      "[DEBUG] Now processing Dos2-Friday-16-02-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in Dos2-Friday-16-02-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Hulk']\n",
      "Harmonized granular labels: {'DoS', 'Benign'}\n",
      "[DEBUG] Now processing DoS1-Thursday-15-02-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in DoS1-Thursday-15-02-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'DoS attacks-GoldenEye', 'DoS attacks-Slowloris']\n",
      "Harmonized granular labels: {'DoS', 'Benign'}\n",
      "[DEBUG] Now processing Infil1-Wednesday-28-02-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in Infil1-Wednesday-28-02-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'Infilteration']\n",
      "Harmonized granular labels: {'Infiltration', 'Benign'}\n",
      "[DEBUG] Now processing infil2-Thursday-01-03-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in infil2-Thursday-01-03-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'Infilteration']\n",
      "Harmonized granular labels: {'Infiltration', 'Benign'}\n",
      "[DEBUG] Now processing BruteForce-Wednesday-14-02-2018_TrafficForML_CICFlowMeter.parquet in CIC_IDS_2018\n",
      "DEBUG: Raw labels in BruteForce-Wednesday-14-02-2018_TrafficForML_CICFlowMeter of CIC_IDS_2018 before harmonization: ['Benign', 'FTP-BruteForce', 'SSH-Bruteforce']\n",
      "Harmonized granular labels: {'FTP-BruteForce', 'SSH-BruteForce', 'Benign'}\n",
      "Total 10 fully processed DataFrames for CIC_IDS_2018.\n",
      "Combined DataFrame shape for CIC_IDS_2018: (7115905, 71)\n",
      "DEBUG: Harmonized granular string labels in CIC_IDS_2018 (before encoding): ['Benign', 'DDoS', 'Web Attack - Brute Force', 'Web Attack - XSS', 'Web Attack - SQL Injection', 'Botnet', 'DoS', 'Infiltration', 'FTP-BruteForce', 'SSH-BruteForce']\n",
      "Label distribution in CIC_IDS_2018 (after granular harmonization):\n",
      "Label\n",
      "Benign                        5759910\n",
      "DDoS                           775955\n",
      "DoS                            196568\n",
      "Botnet                         144535\n",
      "Infiltration                   143952\n",
      "SSH-BruteForce                  94048\n",
      "Web Attack - Brute Force          570\n",
      "Web Attack - XSS                  229\n",
      "Web Attack - SQL Injection         85\n",
      "FTP-BruteForce                     53\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Loading and Preprocessing CIC_IDS_2017 ---\n",
      "[DEBUG] Now processing Botnet-Friday-WorkingHours-Morning.pcap_ISCX.parquet in CIC_IDS_2017\n",
      "DEBUG: Raw labels in Botnet-Friday-WorkingHours-Morning.pcap_ISCX of CIC_IDS_2017 before harmonization: ['Benign', 'Bot']\n",
      "Harmonized granular labels: {'Benign', 'Botnet'}\n",
      "[DEBUG] Now processing Portscan-Friday-WorkingHours-Afternoon.pcap_ISCX.parquet in CIC_IDS_2017\n",
      "DEBUG: Raw labels in Portscan-Friday-WorkingHours-Afternoon.pcap_ISCX of CIC_IDS_2017 before harmonization: ['Benign', 'PortScan']\n",
      "Harmonized granular labels: {'PortScan', 'Benign'}\n",
      "[DEBUG] Now processing Infiltration-Thursday-WorkingHours-Afternoon.pcap_ISCX.parquet in CIC_IDS_2017\n",
      "DEBUG: Raw labels in Infiltration-Thursday-WorkingHours-Afternoon.pcap_ISCX of CIC_IDS_2017 before harmonization: ['Benign', 'Infiltration']\n",
      "Harmonized granular labels: {'Infiltration', 'Benign'}\n",
      "[DEBUG] Now processing WebAttacks-Thursday-WorkingHours-Morning.pcap_ISCX.parquet in CIC_IDS_2017\n",
      "DEBUG: Raw labels in WebAttacks-Thursday-WorkingHours-Morning.pcap_ISCX of CIC_IDS_2017 before harmonization: ['Benign', 'Web Attack � Brute Force', 'Web Attack � XSS', 'Web Attack � Sql Injection']\n",
      "Harmonized granular labels: {'Web Attack - Brute Force', 'Web Attack - SQL Injection', 'Web Attack - XSS', 'Benign'}\n",
      "[DEBUG] Now processing Bruteforce-Tuesday-WorkingHours.pcap_ISCX.parquet in CIC_IDS_2017\n",
      "DEBUG: Raw labels in Bruteforce-Tuesday-WorkingHours.pcap_ISCX of CIC_IDS_2017 before harmonization: ['Benign', 'FTP-Patator', 'SSH-Patator']\n",
      "Harmonized granular labels: {'FTP-BruteForce', 'SSH-BruteForce', 'Benign'}\n",
      "[DEBUG] Now processing DDoS-Friday-WorkingHours-Afternoon.pcap_ISCX.parquet in CIC_IDS_2017\n",
      "DEBUG: Raw labels in DDoS-Friday-WorkingHours-Afternoon.pcap_ISCX of CIC_IDS_2017 before harmonization: ['Benign', 'DDoS']\n",
      "Harmonized granular labels: {'DDoS', 'Benign'}\n",
      "[DEBUG] Now processing Benign-Monday-WorkingHours.pcap_ISCX.parquet in CIC_IDS_2017\n",
      "DEBUG: Raw labels in Benign-Monday-WorkingHours.pcap_ISCX of CIC_IDS_2017 before harmonization: ['Benign']\n",
      "Harmonized granular labels: {'Benign'}\n",
      "[DEBUG] Now processing DoS-Wednesday-WorkingHours.pcap_ISCX.parquet in CIC_IDS_2017\n",
      "DEBUG: Raw labels in DoS-Wednesday-WorkingHours.pcap_ISCX of CIC_IDS_2017 before harmonization: ['Benign', 'DoS slowloris', 'DoS Slowhttptest', 'DoS Hulk', 'DoS GoldenEye', 'Heartbleed']\n",
      "Harmonized granular labels: {'Heartbleed', 'DoS', 'Benign'}\n",
      "Total 8 fully processed DataFrames for CIC_IDS_2017.\n",
      "Combined DataFrame shape for CIC_IDS_2017: (2572642, 71)\n",
      "DEBUG: Harmonized granular string labels in CIC_IDS_2017 (before encoding): ['Benign', 'Botnet', 'PortScan', 'Infiltration', 'Web Attack - Brute Force', 'Web Attack - XSS', 'Web Attack - SQL Injection', 'FTP-BruteForce', 'SSH-BruteForce', 'DDoS', 'DoS', 'Heartbleed']\n",
      "Label distribution in CIC_IDS_2017 (after granular harmonization):\n",
      "Label\n",
      "Benign                        2146901\n",
      "DoS                            193745\n",
      "DDoS                           128014\n",
      "PortScan                        90694\n",
      "FTP-BruteForce                   5931\n",
      "SSH-BruteForce                   3219\n",
      "Botnet                           1948\n",
      "Web Attack - Brute Force         1470\n",
      "Web Attack - XSS                  652\n",
      "Infiltration                       36\n",
      "Web Attack - SQL Injection         21\n",
      "Heartbleed                         11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Aligning Features Across All Datasets ---\n",
      "CIC_IDS_2018 shape after feature alignment (combined): (7115905, 71)\n",
      "  DEBUG: CIC_IDS_2018 Label unique values AFTER alignment (still strings): ['Benign', 'DDoS', 'Web Attack - Brute Force', 'Web Attack - XSS', 'Web Attack - SQL Injection', 'Botnet', 'DoS', 'Infiltration', 'FTP-BruteForce', 'SSH-BruteForce']\n",
      "CIC_IDS_2017 shape after feature alignment (combined): (2572642, 71)\n",
      "  DEBUG: CIC_IDS_2017 Label unique values AFTER alignment (still strings): ['Benign', 'Botnet', 'PortScan', 'Infiltration', 'Web Attack - Brute Force', 'Web Attack - XSS', 'Web Attack - SQL Injection', 'FTP-BruteForce', 'SSH-BruteForce', 'DDoS', 'DoS', 'Heartbleed']\n",
      "Individual DFs for CIC_IDS_2018 aligned to common features.\n",
      "Individual DFs for CIC_IDS_2017 aligned to common features.\n",
      "\n",
      "--- Encoding Labels Consistently (Granular) ---\n",
      "DEBUG: Unique granular labels collected for fitting label_encoder: ['Benign', 'Botnet', 'DDoS', 'DoS', 'FTP-BruteForce', 'Heartbleed', 'Infiltration', 'PortScan', 'SSH-BruteForce', 'Web Attack - Brute Force', 'Web Attack - SQL Injection', 'Web Attack - XSS']\n",
      "DEBUG: label_encoder.classes_ after fit: ['Benign', 'Botnet', 'DDoS', 'DoS', 'FTP-BruteForce', 'Heartbleed', 'Infiltration', 'PortScan', 'SSH-BruteForce', 'Web Attack - Brute Force', 'Web Attack - SQL Injection', 'Web Attack - XSS']\n",
      "DEBUG: ALL_ENCODED_LABELS (encoded granular labels): [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "DEBUG: After granular encoding for CIC_IDS_2018 (combined), first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for CIC_IDS_2017 (combined), first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF DDoS1-Tuesday-20-02-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF Web1-Thursday-22-02-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF Botnet-Friday-02-03-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF DDoS2-Wednesday-21-02-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF Web2-Friday-23-02-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF Dos2-Friday-16-02-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF DoS1-Thursday-15-02-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF Infil1-Wednesday-28-02-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF infil2-Thursday-01-03-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF BruteForce-Wednesday-14-02-2018_TrafficForML_CICFlowMeter, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "Labels in individual DFs for CIC_IDS_2018 encoded.\n",
      "DEBUG: After granular encoding for individual DF Botnet-Friday-WorkingHours-Morning.pcap_ISCX, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF Portscan-Friday-WorkingHours-Afternoon.pcap_ISCX, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF Infiltration-Thursday-WorkingHours-Afternoon.pcap_ISCX, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF WebAttacks-Thursday-WorkingHours-Morning.pcap_ISCX, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF Bruteforce-Tuesday-WorkingHours.pcap_ISCX, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF DDoS-Friday-WorkingHours-Afternoon.pcap_ISCX, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF Benign-Monday-WorkingHours.pcap_ISCX, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "DEBUG: After granular encoding for individual DF DoS-Wednesday-WorkingHours.pcap_ISCX, first 5 encoded labels: [0, 0, 0, 0, 0]\n",
      "Labels in individual DFs for CIC_IDS_2017 encoded.\n",
      "\n",
      "--- Creating Broad Label Mapper and Encoder ---\n",
      "Broad labels defined: ['Benign', 'Botnet', 'Brute Force', 'DDoS', 'DoS', 'Heartbleed', 'Infiltration', 'PortScan', 'Web Attack - Brute Force', 'Web Attack - SQL Injection', 'Web Attack - XSS']\n",
      "\n",
      "--- Applying Broad Label Mapping to DataFrames ---\n",
      "DEBUG: CIC_IDS_2018 'BroadLabel' unique values after mapping: [0, 3, 8, 10, 9, 1, 4, 6, 2]\n",
      "DEBUG: CIC_IDS_2017 'BroadLabel' unique values after mapping: [0, 1, 7, 6, 8, 10, 9, 2, 3, 4, 5]\n",
      "DEBUG: Individual DF DDoS1-Tuesday-20-02-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 3]\n",
      "DEBUG: Individual DF Web1-Thursday-22-02-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 8, 10, 9]\n",
      "DEBUG: Individual DF Botnet-Friday-02-03-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 1]\n",
      "DEBUG: Individual DF DDoS2-Wednesday-21-02-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 3]\n",
      "DEBUG: Individual DF Web2-Friday-23-02-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 8, 10, 9]\n",
      "DEBUG: Individual DF Dos2-Friday-16-02-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 4]\n",
      "DEBUG: Individual DF DoS1-Thursday-15-02-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 4]\n",
      "DEBUG: Individual DF Infil1-Wednesday-28-02-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 6]\n",
      "DEBUG: Individual DF infil2-Thursday-01-03-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 6]\n",
      "DEBUG: Individual DF BruteForce-Wednesday-14-02-2018_TrafficForML_CICFlowMeter 'BroadLabel' unique values after mapping: [0, 2]\n",
      "DEBUG: Individual DF Botnet-Friday-WorkingHours-Morning.pcap_ISCX 'BroadLabel' unique values after mapping: [0, 1]\n",
      "DEBUG: Individual DF Portscan-Friday-WorkingHours-Afternoon.pcap_ISCX 'BroadLabel' unique values after mapping: [0, 7]\n",
      "DEBUG: Individual DF Infiltration-Thursday-WorkingHours-Afternoon.pcap_ISCX 'BroadLabel' unique values after mapping: [0, 6]\n",
      "DEBUG: Individual DF WebAttacks-Thursday-WorkingHours-Morning.pcap_ISCX 'BroadLabel' unique values after mapping: [0, 8, 10, 9]\n",
      "DEBUG: Individual DF Bruteforce-Tuesday-WorkingHours.pcap_ISCX 'BroadLabel' unique values after mapping: [0, 2]\n",
      "DEBUG: Individual DF DDoS-Friday-WorkingHours-Afternoon.pcap_ISCX 'BroadLabel' unique values after mapping: [0, 3]\n",
      "DEBUG: Individual DF Benign-Monday-WorkingHours.pcap_ISCX 'BroadLabel' unique values after mapping: [0]\n",
      "DEBUG: Individual DF DoS-Wednesday-WorkingHours.pcap_ISCX 'BroadLabel' unique values after mapping: [0, 4, 5]\n",
      "WARNING: Found BroadLabels (decoded) in data not in TARGET_ATTACK_LABELS_STR_BROAD: {'DoS'}\n",
      "INFO: Expected BroadLabels (from TARGET_ATTACK_LABELS_STR_BROAD) not found in data: {'Web Attack', 'Other Attack'}\n",
      "\n",
      "################################################################################\n",
      "### AE-only: Train on CIC_IDS_2017  |  Test on CIC_IDS_2018\n",
      "################################################################################\n",
      "Train sequences: (246866, 10, 70), Test sequences: (673243, 10, 70)\n",
      "[INFO] Found AE at lstmmodels/ae_2017_sl10_nf70_lat64_enc128_dec128.h5. Attempting to load AE/Encoder for 2017 (cfg: sl10_nf70_lat64_enc128_dec128) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 23:30:55.291161: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:30:55.298083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:30:55.302891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:30:55.730826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:30:55.733460: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:30:55.735946: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:30:56.160713: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:30:56.162592: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:30:56.164774: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:30:56.701565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:30:56.705981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:30:56.710538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:30:58.700687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:30:58.703162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:30:58.706146: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:30:59.414869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:30:59.417654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:30:59.420395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:30:59.855497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:30:59.858776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:30:59.861558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:31:00.379227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:31:00.382473: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:31:00.385092: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Global AE threshold (q=0.995, k=6.0): 0.805462\n",
      "\n",
      "--- Overall AE-only (binary) on CIC_IDS_2018 ---\n",
      "Accuracy=0.5227  Precision=0.1838  Recall=0.6700  F1=0.2885  ROC-AUC=0.6118\n",
      "Confusion matrix (rows=true [Benign,Attack], cols=pred):\n",
      "[[286773 289246]\n",
      " [ 32087  65137]]\n",
      "\n",
      "################################################################################\n",
      "### AE-only: Train on CIC_IDS_2018  |  Test on CIC_IDS_2017\n",
      "################################################################################\n",
      "Train sequences: (673243, 10, 70), Test sequences: (246866, 10, 70)\n",
      "[INFO] Found AE at lstmmodels/ae_2018_sl10_nf70_lat64_enc128_dec128.h5. Attempting to load AE/Encoder for 2018 (cfg: sl10_nf70_lat64_enc128_dec128) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 23:43:31.775097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:43:31.801529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:43:31.807073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:43:33.310325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:43:33.314953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:43:33.318204: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:43:33.996118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:43:34.000082: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:43:34.003665: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:43:34.743174: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:43:34.746074: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:43:34.748740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:43:35.304486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:43:35.309031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:43:35.312069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:43:36.279898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:43:36.285323: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:43:36.289453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:43:36.923684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:43:36.927991: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:43:36.931605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2025-09-05 23:43:37.533323: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2025-09-05 23:43:37.537983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2025-09-05 23:43:37.543011: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Global AE threshold (q=0.995, k=6.0): 0.373201\n",
      "\n",
      "--- Overall AE-only (binary) on CIC_IDS_2017 ---\n",
      "Accuracy=0.6903  Precision=0.2845  Recall=0.9085  F1=0.4333  ROC-AUC=0.8892\n",
      "Confusion matrix (rows=true [Benign,Attack], cols=pred):\n",
      "[[141187  73510]\n",
      " [  2942  29227]]\n",
      "\n",
      "================================================================================\n",
      "RESULTS  Train=CIC_IDS_2017  Test=CIC_IDS_2018\n",
      "Accuracy: 0.5227  Precision: 0.1838  Recall: 0.6700  F1: 0.2885  ROC-AUC: 0.6118\n",
      "Threshold used: 0.805462\n",
      "\n",
      "--- Per-Day Metrics (AE-only, binary) ---\n",
      "\n",
      "Day: DDoS1-Tuesday-20-02-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 0.282660\n",
      "  Overall  -> Acc=0.7067  Prec=0.6706  Rec=0.9775  F1=0.7955  ROC-AUC=0.7911\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[13436, 27628], [1294, 56254]]  Support: {'benign': 41064, 'attack': 57548}\n",
      "  DoS     -> Acc=0.3272  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[13436, 27628], [0, 0]]  Support: {'benign': 41064, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.7067  Prec=0.6706  Rec=0.9775  F1=0.7955  ROC-AUC=0.7911\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[13436, 27628], [1294, 56254]]  Support: {'benign': 41064, 'DDoS': 57548}\n",
      "\n",
      "Day: Web1-Thursday-22-02-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 0.805462\n",
      "  Overall  -> Acc=0.4349  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[39207, 50949], [0, 0]]  Support: {'benign': 90156, 'attack': 0}\n",
      "  DoS     -> Acc=0.4350  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[39207, 50918], [0, 0]]  Support: {'benign': 90125, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.4350  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[39207, 50918], [0, 0]]  Support: {'benign': 90125, 'DDoS': 0}\n",
      "\n",
      "Day: Botnet-Friday-02-03-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 0.805462\n",
      "  Overall  -> Acc=0.2795  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[22917, 59073], [0, 0]]  Support: {'benign': 81990, 'attack': 0}\n",
      "  DoS     -> Acc=0.3392  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[22917, 44645], [0, 0]]  Support: {'benign': 67562, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.3392  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[22917, 44645], [0, 0]]  Support: {'benign': 67562, 'DDoS': 0}\n",
      "\n",
      "Day: DDoS2-Wednesday-21-02-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 6.850107\n",
      "  Overall  -> Acc=0.7857  Prec=0.7454  Rec=0.6097  F1=0.6708  ROC-AUC=0.5913\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[31856, 4186], [7844, 12254]]  Support: {'benign': 36042, 'attack': 20098}\n",
      "  DoS     -> Acc=0.8839  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[31856, 4186], [0, 0]]  Support: {'benign': 36042, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.7857  Prec=0.7454  Rec=0.6097  F1=0.6708  ROC-AUC=0.5913\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[31856, 4186], [7844, 12254]]  Support: {'benign': 36042, 'DDoS': 20098}\n",
      "\n",
      "Day: Web2-Friday-23-02-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 0.805462\n",
      "  Overall  -> Acc=0.4359  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[39461, 51057], [0, 0]]  Support: {'benign': 90518, 'attack': 0}\n",
      "  DoS     -> Acc=0.4362  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[39461, 51006], [0, 0]]  Support: {'benign': 90467, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.4362  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[39461, 51006], [0, 0]]  Support: {'benign': 90467, 'DDoS': 0}\n",
      "\n",
      "Day: Dos2-Friday-16-02-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 0.046679\n",
      "  Overall  -> Acc=0.5467  Prec=0.3075  Rec=0.6776  F1=0.4230  ROC-AUC=0.5521\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[22522, 22153], [4679, 9836]]  Support: {'benign': 44675, 'attack': 14515}\n",
      "  DoS     -> Acc=0.5467  Prec=0.3075  Rec=0.6776  F1=0.4230  ROC-AUC=0.5521\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[22522, 22153], [4679, 9836]]  Support: {'benign': 44675, 'DoS': 14515}\n",
      "  DDoS    -> Acc=0.5041  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[22522, 22153], [0, 0]]  Support: {'benign': 44675, 'DDoS': 0}\n",
      "\n",
      "Day: DoS1-Thursday-15-02-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 0.010841\n",
      "  Overall  -> Acc=0.0605  Prec=0.0586  Rec=0.9996  F1=0.1107  ROC-AUC=0.3615\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[176, 82388], [2, 5128]]  Support: {'benign': 82564, 'attack': 5130}\n",
      "  DoS     -> Acc=0.0605  Prec=0.0586  Rec=0.9996  F1=0.1107  ROC-AUC=0.3615\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[176, 82388], [2, 5128]]  Support: {'benign': 82564, 'DoS': 5130}\n",
      "  DDoS    -> Acc=0.0021  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[176, 82388], [0, 0]]  Support: {'benign': 82564, 'DDoS': 0}\n",
      "\n",
      "Day: Infil1-Wednesday-28-02-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 0.805462\n",
      "  Overall  -> Acc=0.3254  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[16716, 34655], [0, 0]]  Support: {'benign': 51371, 'attack': 0}\n",
      "  DoS     -> Acc=0.3290  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[14901, 30385], [0, 0]]  Support: {'benign': 45286, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.3290  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[14901, 30385], [0, 0]]  Support: {'benign': 45286, 'DDoS': 0}\n",
      "\n",
      "Day: infil2-Thursday-01-03-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 0.805462\n",
      "  Overall  -> Acc=0.3483  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[10031, 18771], [0, 0]]  Support: {'benign': 28802, 'attack': 0}\n",
      "  DoS     -> Acc=0.3174  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[6522, 14026], [0, 0]]  Support: {'benign': 20548, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.3174  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[6522, 14026], [0, 0]]  Support: {'benign': 20548, 'DDoS': 0}\n",
      "\n",
      "Day: BruteForce-Wednesday-14-02-2018_TrafficForML_CICFlowMeter\n",
      "  Threshold: 0.805462\n",
      "  Overall  -> Acc=0.6966  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[46750, 20363], [0, 0]]  Support: {'benign': 67113, 'attack': 0}\n",
      "  DoS     -> Acc=0.6471  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[37337, 20361], [0, 0]]  Support: {'benign': 57698, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.6471  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[37337, 20361], [0, 0]]  Support: {'benign': 57698, 'DDoS': 0}\n",
      "\n",
      "================================================================================\n",
      "RESULTS  Train=CIC_IDS_2018  Test=CIC_IDS_2017\n",
      "Accuracy: 0.6903  Precision: 0.2845  Recall: 0.9085  F1: 0.4333  ROC-AUC: 0.8892\n",
      "Threshold used: 0.373201\n",
      "\n",
      "--- Per-Day Metrics (AE-only, binary) ---\n",
      "\n",
      "Day: Botnet-Friday-WorkingHours-Morning.pcap_ISCX\n",
      "  Threshold: 0.373201\n",
      "  Overall  -> Acc=0.6978  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[12843, 5561], [0, 0]]  Support: {'benign': 18404, 'attack': 0}\n",
      "  DoS     -> Acc=0.6975  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[12706, 5510], [0, 0]]  Support: {'benign': 18216, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.6975  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[12706, 5510], [0, 0]]  Support: {'benign': 18216, 'DDoS': 0}\n",
      "\n",
      "Day: Portscan-Friday-WorkingHours-Afternoon.pcap_ISCX\n",
      "  Threshold: 0.373201\n",
      "  Overall  -> Acc=0.8030  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[17166, 4211], [0, 0]]  Support: {'benign': 21377, 'attack': 0}\n",
      "  DoS     -> Acc=0.7208  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[8874, 3438], [0, 0]]  Support: {'benign': 12312, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.7208  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[8874, 3438], [0, 0]]  Support: {'benign': 12312, 'DDoS': 0}\n",
      "\n",
      "Day: Infiltration-Thursday-WorkingHours-Afternoon.pcap_ISCX\n",
      "  Threshold: 0.373201\n",
      "  Overall  -> Acc=0.7392  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[18685, 6594], [0, 0]]  Support: {'benign': 25279, 'attack': 0}\n",
      "  DoS     -> Acc=0.7393  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[18685, 6588], [0, 0]]  Support: {'benign': 25273, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.7393  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[18685, 6588], [0, 0]]  Support: {'benign': 25273, 'DDoS': 0}\n",
      "\n",
      "Day: WebAttacks-Thursday-WorkingHours-Morning.pcap_ISCX\n",
      "  Threshold: 0.373201\n",
      "  Overall  -> Acc=0.7298  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[11981, 4436], [0, 0]]  Support: {'benign': 16417, 'attack': 0}\n",
      "  DoS     -> Acc=0.7295  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[11812, 4379], [0, 0]]  Support: {'benign': 16191, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.7295  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[11812, 4379], [0, 0]]  Support: {'benign': 16191, 'DDoS': 0}\n",
      "\n",
      "Day: Bruteforce-Tuesday-WorkingHours.pcap_ISCX\n",
      "  Threshold: 0.373201\n",
      "  Overall  -> Acc=0.6516  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[27471, 14691], [0, 0]]  Support: {'benign': 42162, 'attack': 0}\n",
      "  DoS     -> Acc=0.6529  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[26907, 14306], [0, 0]]  Support: {'benign': 41213, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.6529  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[26907, 14306], [0, 0]]  Support: {'benign': 41213, 'DDoS': 0}\n",
      "\n",
      "Day: DDoS-Friday-WorkingHours-Afternoon.pcap_ISCX\n",
      "  Threshold: 2.158629\n",
      "  Overall  -> Acc=0.7554  Prec=0.7618  Rec=0.8351  F1=0.7968  ROC-AUC=0.6832\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[6157, 3344], [2112, 10695]]  Support: {'benign': 9501, 'attack': 12807}\n",
      "  DoS     -> Acc=0.6480  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[6157, 3344], [0, 0]]  Support: {'benign': 9501, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.7554  Prec=0.7618  Rec=0.8351  F1=0.7968  ROC-AUC=0.6832\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[6157, 3344], [2112, 10695]]  Support: {'benign': 9501, 'DDoS': 12807}\n",
      "\n",
      "Day: Benign-Monday-WorkingHours.pcap_ISCX\n",
      "  Threshold: 0.373201\n",
      "  Overall  -> Acc=0.6631  Prec=0.0000  Rec=0.0000  F1=0.0000  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[33329, 16936], [0, 0]]  Support: {'benign': 50265, 'attack': 0}\n",
      "  DoS     -> Acc=0.6631  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[33329, 16936], [0, 0]]  Support: {'benign': 50265, 'DoS': 0}\n",
      "  DDoS    -> Acc=0.6631  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[33329, 16936], [0, 0]]  Support: {'benign': 50265, 'DDoS': 0}\n",
      "\n",
      "Day: DoS-Wednesday-WorkingHours.pcap_ISCX\n",
      "  Threshold: 3.950219\n",
      "  Overall  -> Acc=0.9157  Prec=0.8909  Rec=0.8374  F1=0.8633  ROC-AUC=0.9239\n",
      "              CM (rows=true [Benign,Attack], cols=pred): [[39642, 1991], [3157, 16259]]  Support: {'benign': 41633, 'attack': 19416}\n",
      "  DoS     -> Acc=0.9157  Prec=0.8910  Rec=0.8374  F1=0.8633  ROC-AUC=0.9239\n",
      "              CM (rows=true [Benign,DoS], cols=pred): [[39642, 1990], [3157, 16259]]  Support: {'benign': 41632, 'DoS': 19416}\n",
      "  DDoS    -> Acc=0.9522  Prec=nan  Rec=nan  F1=nan  ROC-AUC=nan\n",
      "              CM (rows=true [Benign,DDoS], cols=pred): [[39642, 1990], [0, 0]]  Support: {'benign': 41632, 'DDoS': 0}\n"
     ]
    }
   ],
   "source": [
    "def run_cross_ae_only(\n",
    "        seq_len=20, stride=None, ae_epochs=10, batch_size=256, verbose=1, per_day=True,\n",
    "                      use_day_threshold=False, q_global=0.995,qlow_day=0.60,qhigh_day=0.99, per_attack_mode=\"max_f1\",\n",
    "                      per_attack_target_precision=0.60,k=6.0,build_lstm_autoencoder_fn=None):\n",
    "    (\n",
    "        all_combined_dfs,\n",
    "        all_individual_dfs_by_dataset,\n",
    "        _,\n",
    "        _,\n",
    "        common_features,\n",
    "        broad_label_mapper,\n",
    "        broad_label_encoder\n",
    "    ) = load_and_align_all_data(DATASET_PATHS)\n",
    "\n",
    "    tf.keras.utils.set_random_seed(42)\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "    if stride is None:\n",
    "        stride = max(1, seq_len // 2)  # overlapping by default\n",
    "\n",
    "    scenarios = [\n",
    "        (\"CIC_IDS_2017\", \"CIC_IDS_2018\"),\n",
    "        (\"CIC_IDS_2018\", \"CIC_IDS_2017\"),\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for train_name, test_name in scenarios:\n",
    "        print(\"\\n\" + \"#\"*80)\n",
    "        print(f\"### AE-only: Train on {train_name}  |  Test on {test_name}\")\n",
    "        print(\"#\"*80)\n",
    "\n",
    "        train_df = all_combined_dfs[train_name]\n",
    "        test_df  = all_combined_dfs[test_name]\n",
    "\n",
    "        X_train_flat  = train_df[common_features].fillna(0.0).to_numpy(dtype=np.float32)\n",
    "        y_train_flat  = train_df[\"BroadLabel\"].astype(int).to_numpy()\n",
    "        X_test_flat   = test_df[common_features].fillna(0.0).to_numpy(dtype=np.float32)\n",
    "        y_test_flat   = test_df[\"BroadLabel\"].astype(int).to_numpy()\n",
    "\n",
    "        benign_id = broad_label_encoder.transform([\"Benign\"])[0]\n",
    "        dos_id    = broad_label_encoder.transform([\"DoS\"])[0]\n",
    "        ddos_id   = broad_label_encoder.transform([\"DDoS\"])[0]\n",
    "        allowed_labels = {benign_id, dos_id, ddos_id}\n",
    "\n",
    "        # Filter to Benign/DoS/DDoS\n",
    "        train_mask = np.isin(y_train_flat, list(allowed_labels))\n",
    "        X_train_flat, y_train_flat = X_train_flat[train_mask], y_train_flat[train_mask]\n",
    "        test_mask = np.isin(y_test_flat, list(allowed_labels))\n",
    "        X_test_flat,  y_test_flat  = X_test_flat[test_mask], y_test_flat[test_mask]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_flat = scaler.fit_transform(X_train_flat).astype(np.float32)\n",
    "        X_test_flat  = scaler.transform(X_test_flat).astype(np.float32)\n",
    "\n",
    "        X_train_seq, y_train_seq = build_sequences_matrix(X_train_flat, y_train_flat, seq_len=seq_len, stride=stride)\n",
    "        X_test_seq,  y_test_seq  = build_sequences_matrix(X_test_flat,  y_test_flat,  seq_len=seq_len, stride=stride)\n",
    "        print(f\"Train sequences: {X_train_seq.shape}, Test sequences: {X_test_seq.shape}\")\n",
    "\n",
    "        # Stage 1: AE on Benign-only\n",
    "        X_ae = X_train_seq[y_train_seq == benign_id]\n",
    "        X_ae_tr, X_ae_val = time_ordered_split(X_ae, val_ratio=0.1)\n",
    "\n",
    "        seq_len_eff = X_train_seq.shape[1]\n",
    "        n_features  = X_train_seq.shape[2]\n",
    "        ae, encoder, history = train_or_load_ae(\n",
    "            X_train_seq=X_ae_tr,\n",
    "            seq_len=seq_len_eff,\n",
    "            n_features=n_features,\n",
    "            train_name=train_name,\n",
    "            ae_epochs=ae_epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            latent=64,\n",
    "            enc_units=(128,),\n",
    "            dec_units=(128,),\n",
    "            models_dir=\"lstmmodels\",\n",
    "           \n",
    "            compile_loaded=False,\n",
    "            X_val_seq=X_ae_val,\n",
    "            shuffle_fit=False,\n",
    "            build_lstm_autoencoder_fn=build_lstm_autoencoder\n",
    "        )\n",
    "\n",
    "        def compute_recon_error(ae_model, X):\n",
    "            recon = ae_model.predict(X, verbose=0)\n",
    "            return np.mean((X - recon) ** 2, axis=(1,2))\n",
    "\n",
    "        # GLOBAL threshold from TRAIN benign errors\n",
    "        benign_train_errors = compute_recon_error(ae, X_ae_tr) if X_ae_tr.size else np.array([])\n",
    "        thr_global = choose_threshold_global(benign_train_errors, q=q_global, k=k)\n",
    "        print(f\"[INFO] Global AE threshold (q={q_global}, k={k}): {thr_global:.6f}\")\n",
    "\n",
    "        # Overall test: binary detection Attack vs Benign using AE error\n",
    "        err_test = compute_recon_error(ae, X_test_seq)\n",
    "\n",
    "        y_true_attack = np.isin(y_test_seq, [dos_id, ddos_id]).astype(int)  # 1=Attack, 0=Benign\n",
    "\n",
    "        \n",
    "        thr_used = thr_global # overall report uses global (keep simple)\n",
    "\n",
    "        y_pred_attack = (err_test > thr_used).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_true_attack, y_pred_attack)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true_attack, y_pred_attack, average='binary', zero_division=0)\n",
    "\n",
    "\n",
    "        try:\n",
    "            has_ben = (y_true_attack == 0).any()\n",
    "            has_att = (y_true_attack == 1).any()\n",
    "            roc = roc_auc_score(y_true_attack, err_test) if (has_ben and has_att) else np.nan\n",
    "        except Exception:\n",
    "            roc = np.nan\n",
    "        cm = confusion_matrix(y_true_attack, y_pred_attack, labels=[0,1])\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Overall AE-only (binary) on {test_name} ---\")\n",
    "        print(f\"Accuracy={acc:.4f}  Precision={p:.4f}  Recall={r:.4f}  F1={f1:.4f}  ROC-AUC={roc:.4f}\")\n",
    "        cm = confusion_matrix(y_true_attack, y_pred_attack, labels=[0,1])\n",
    "        print(\"Confusion matrix (rows=true [Benign,Attack], cols=pred):\")\n",
    "        print(cm)\n",
    "\n",
    "        results[(train_name, test_name)] = {\n",
    "            \"overall_binary\": {\n",
    "                \"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f1, \"roc_auc\": roc,\n",
    "                \"threshold\": thr_used, \"cm\": cm.tolist()\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Per-day evaluation (binary)\n",
    "        if per_day:\n",
    "            per_day_metrics = {}\n",
    "            indiv = all_individual_dfs_by_dataset[test_name]\n",
    "            for day_name, df_day in indiv.items():\n",
    "                if df_day.empty: \n",
    "                    continue\n",
    "                    \n",
    "                Xd = df_day[common_features].fillna(0.0).to_numpy(dtype=np.float32)\n",
    "                yd = df_day[\"BroadLabel\"].astype(int).to_numpy()\n",
    "                Xd = scaler.transform(Xd).astype(np.float32)\n",
    "                Xd_seq, yd_seq = build_sequences_matrix(Xd, yd, seq_len=seq_len, stride=stride)\n",
    "                if len(yd_seq) == 0:\n",
    "                    continue\n",
    "\n",
    "                # AE errors\n",
    "                err_day = compute_recon_error(ae, Xd_seq)\n",
    "\n",
    "\n",
    "                # Overall day binary labels\n",
    "                y_true_day_overall = np.isin(yd_seq, [dos_id, ddos_id]).astype(int)\n",
    "                \n",
    "                if use_day_threshold:\n",
    "                    thr_day = choose_day_threshold_by_pr(\n",
    "                        err_day, y_true_day_overall, fallback_thr=thr_used, mode=\"max_f1\"\n",
    "                    )\n",
    "                else:\n",
    "                    thr_day = thr_used\n",
    "\n",
    "                y_pred_day_overall = (err_day > thr_day).astype(int)\n",
    "                accd = accuracy_score(y_true_day_overall, y_pred_day_overall)\n",
    "                pd_, rd_, f1d, _ = precision_recall_fscore_support(\n",
    "                    y_true_day_overall, y_pred_day_overall, average='binary', zero_division=0\n",
    "                )\n",
    "                try:\n",
    "                    has_ben = (y_true_day_overall == 0).any()\n",
    "                    has_att = (y_true_day_overall == 1).any()\n",
    "                    rocd = roc_auc_score(y_true_day_overall, err_day) if (has_ben and has_att) else np.nan\n",
    "                except Exception:\n",
    "                    rocd = np.nan\n",
    "                cm_day = confusion_matrix(y_true_day_overall, y_pred_day_overall, labels=[0,1])\n",
    "\n",
    "                # Per-attack (DoS / DDoS) binary reports with attack-specific thresholds\n",
    "                per_attack = {}\n",
    "                for attack_name, attack_id in [(\"DoS\", dos_id), (\"DDoS\", ddos_id)]:\n",
    "                    mask = np.isin(yd_seq, [benign_id, attack_id])\n",
    "                    if not mask.any():\n",
    "                        continue\n",
    "                    err_sub = err_day[mask]\n",
    "                    y_true_sub = (yd_seq[mask] == attack_id).astype(int)\n",
    "\n",
    "                    thr_sub = choose_subset_thr(\n",
    "                        err_sub, y_true_sub, fallback_thr=thr_day,\n",
    "                        mode=per_attack_mode, target_p=per_attack_target_precision\n",
    "                    )\n",
    "                    y_pred_sub = (err_sub > thr_sub).astype(int)\n",
    "\n",
    "                    has_ben_sub = (y_true_sub == 0).any()\n",
    "                    has_att_sub = (y_true_sub == 1).any()\n",
    "\n",
    "                    acc_sub = accuracy_score(y_true_sub, y_pred_sub) if (has_ben_sub or has_att_sub) else np.nan\n",
    "                    prec_sub, rec_sub, f1_sub = (np.nan, np.nan, np.nan)\n",
    "                    if has_ben_sub and has_att_sub:\n",
    "                        prec_sub, rec_sub, f1_sub, _ = precision_recall_fscore_support(\n",
    "                            y_true_sub, y_pred_sub, average='binary', zero_division=0\n",
    "                        )\n",
    "                    try:\n",
    "                        roc_sub = roc_auc_score(y_true_sub, err_sub) if (has_ben_sub and has_att_sub) else np.nan\n",
    "                    except Exception:\n",
    "                        roc_sub = np.nan\n",
    "\n",
    "                    cm_sub = confusion_matrix(y_true_sub, y_pred_sub, labels=[0,1])\n",
    "  \n",
    "\n",
    "                    per_attack[attack_name] = {\n",
    "                        \"threshold\": thr_sub,\n",
    "                        \"accuracy\": acc_sub,\n",
    "                        \"precision\": prec_sub,\n",
    "                        \"recall\": rec_sub,\n",
    "                        \"f1\": f1_sub,\n",
    "                        \"roc_auc\": roc_sub,\n",
    "                        \"cm\": cm_sub.tolist(),\n",
    "                        \"support\": {\n",
    "                            \"benign\": int((y_true_sub == 0).sum()),\n",
    "                            attack_name: int((y_true_sub == 1).sum())\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                # Store per-day metrics\n",
    "                per_day_metrics[day_name] = {\n",
    "                    \"threshold\": thr_day,\n",
    "                    \"overall_binary\": {\n",
    "                        \"accuracy\": accd,\n",
    "                        \"precision\": pd_,\n",
    "                        \"recall\": rd_,\n",
    "                        \"f1\": f1d,\n",
    "                        \"roc_auc\": rocd,\n",
    "                        \"cm\": cm_day.tolist(),\n",
    "                        \"support\": {\n",
    "                            \"benign\": int((y_true_day_overall == 0).sum()),\n",
    "                            \"attack\": int((y_true_day_overall == 1).sum())\n",
    "                        }\n",
    "                    },\n",
    "                    \"per_attack_binary\": per_attack\n",
    "                }\n",
    "\n",
    "            results[(train_name, test_name)][\"per_day_binary\"] = per_day_metrics\n",
    "        # Cleanup\n",
    "        del ae, encoder, X_train_seq, X_test_seq, X_train_flat, X_test_flat, X_ae, X_ae_tr, X_ae_val\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "    return results\n",
    "\n",
    " \n",
    "# ------------------------------------------------------------\n",
    "# 5) Run (AE-only) — printing per-day DoS/DDoS binary reports\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    out = run_cross_ae_only(\n",
    "        seq_len=10,\n",
    "        stride=10,              # try 5 for overlap\n",
    "        ae_epochs=10,\n",
    "        batch_size=256,\n",
    "        verbose=1,\n",
    "        per_day=True,\n",
    "        use_day_threshold=True,\n",
    "        q_global=0.995,\n",
    "        qlow_day=0.60,\n",
    "        qhigh_day=0.99,\n",
    "        k=6.0,\n",
    "        per_attack_mode=\"max_f1\",\n",
    "        per_attack_target_precision=0.60,\n",
    "        build_lstm_autoencoder_fn=build_lstm_autoencoder \n",
    "    )\n",
    "\n",
    "    # Pretty print overall AE-only (binary) metrics\n",
    "    for (tr, te), res in out.items():\n",
    "        ov = res[\"overall_binary\"]\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"RESULTS  Train={tr}  Test={te}\")\n",
    "        print(f\"Accuracy: {ov['accuracy']:.4f}  Precision: {ov['precision']:.4f}  Recall: {ov['recall']:.4f}  F1: {ov['f1']:.4f}  ROC-AUC: {ov['roc_auc']:.4f}\")\n",
    "        print(f\"Threshold used: {ov['threshold']:.6f}\")\n",
    "\n",
    "        # Per-day AE-only (binary) metrics, including per-attack reports\n",
    "        if \"per_day_binary\" in res:\n",
    "            print(\"\\n--- Per-Day Metrics (AE-only, binary) ---\")\n",
    "            for day, m in res[\"per_day_binary\"].items():\n",
    "                print(f\"\\nDay: {day}\")\n",
    "                print(f\"  Threshold: {m['threshold']:.6f}\")\n",
    "                o = m[\"overall_binary\"]\n",
    "                print(f\"  Overall  -> Acc={o['accuracy']:.4f}  Prec={o['precision']:.4f}  Rec={o['recall']:.4f}  F1={o['f1']:.4f}  ROC-AUC={o['roc_auc']:.4f}\")\n",
    "                print(f\"              CM (rows=true [Benign,Attack], cols=pred): {o['cm']}  Support: {o['support']}\")\n",
    "                # Per-attack binary reports\n",
    "                for atk_name, a in m.get(\"per_attack_binary\", {}).items():\n",
    "                    print(f\"  {atk_name:<7} -> Acc={a['accuracy']:.4f}  Prec={a['precision']:.4f}  Rec={a['recall']:.4f}  F1={a['f1']:.4f}  ROC-AUC={a['roc_auc']:.4f}\")\n",
    "                    print(f\"              CM (rows=true [Benign,{atk_name}], cols=pred): {a['cm']}  Support: {a['support']}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff78a9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
